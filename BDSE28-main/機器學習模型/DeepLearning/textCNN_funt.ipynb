{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# from gensim.models import word2vec\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from gensim.models import word2vec\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('job7_df_all.csv', encoding='utf-8-sig')\n",
    "# df = pd.read_csv('job7_keyword.csv', encoding='utf-8-sig')\n",
    "# model = word2vec.Word2Vec.load('word2vec_new.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>...</th>\n",
       "      <th>c55</th>\n",
       "      <th>c56</th>\n",
       "      <th>c57</th>\n",
       "      <th>c58</th>\n",
       "      <th>c59</th>\n",
       "      <th>c60</th>\n",
       "      <th>c61</th>\n",
       "      <th>c62</th>\n",
       "      <th>c63</th>\n",
       "      <th>c64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>465</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>84</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133</td>\n",
       "      <td>244</td>\n",
       "      <td>119</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>29</td>\n",
       "      <td>395</td>\n",
       "      <td>206</td>\n",
       "      <td>187</td>\n",
       "      <td>418</td>\n",
       "      <td>248</td>\n",
       "      <td>226</td>\n",
       "      <td>5</td>\n",
       "      <td>439</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>353</td>\n",
       "      <td>88</td>\n",
       "      <td>476</td>\n",
       "      <td>36</td>\n",
       "      <td>248</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>465</td>\n",
       "      <td>409</td>\n",
       "      <td>110</td>\n",
       "      <td>476</td>\n",
       "      <td>374</td>\n",
       "      <td>248</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24091</th>\n",
       "      <td>159</td>\n",
       "      <td>324</td>\n",
       "      <td>382</td>\n",
       "      <td>148</td>\n",
       "      <td>231</td>\n",
       "      <td>496</td>\n",
       "      <td>437</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24092</th>\n",
       "      <td>159</td>\n",
       "      <td>324</td>\n",
       "      <td>382</td>\n",
       "      <td>108</td>\n",
       "      <td>231</td>\n",
       "      <td>437</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24093</th>\n",
       "      <td>440</td>\n",
       "      <td>454</td>\n",
       "      <td>551</td>\n",
       "      <td>263</td>\n",
       "      <td>423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24094</th>\n",
       "      <td>159</td>\n",
       "      <td>324</td>\n",
       "      <td>498</td>\n",
       "      <td>577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24095</th>\n",
       "      <td>353</td>\n",
       "      <td>88</td>\n",
       "      <td>465</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24096 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c0   c1   c2   c3   c4   c5   c6   c7   c8   c9  ...  c55  c56  c57  \\\n",
       "0      149  465   29    1   64   84  354    0    0    0  ...    0    0    0   \n",
       "1      133  244  119  462    0    0    0    0    0    0  ...    0    0    0   \n",
       "2       88   29  395  206  187  418  248  226    5  439  ...    0    0    0   \n",
       "3      149  353   88  476   36  248  110    5  106    0  ...    0    0    0   \n",
       "4      149  465  409  110  476  374  248  110    5    0  ...    0    0    0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "24091  159  324  382  148  231  496  437  519    0    0  ...    0    0    0   \n",
       "24092  159  324  382  108  231  437  519    0    0    0  ...    0    0    0   \n",
       "24093  440  454  551  263  423    0    0    0    0    0  ...    0    0    0   \n",
       "24094  159  324  498  577    0    0    0    0    0    0  ...    0    0    0   \n",
       "24095  353   88  465    1    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "       c58  c59  c60  c61  c62  c63  c64  \n",
       "0        0    0    0    0    0    0    0  \n",
       "1        0    0    0    0    0    0    0  \n",
       "2        0    0    0    0    0    0    0  \n",
       "3        0    0    0    0    0    0    0  \n",
       "4        0    0    0    0    0    0    0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "24091    0    0    0    0    0    0    0  \n",
       "24092    0    0    0    0    0    0    0  \n",
       "24093    0    0    0    0    0    0    0  \n",
       "24094    0    0    0    0    0    0    0  \n",
       "24095    0    0    0    0    0    0    0  \n",
       "\n",
       "[24096 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c0 - c57, 工作內容提取最大65個字 轉成BoW\n",
    "df_all.iloc[:,705:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(df_all.iloc[:,705:-1],\\\n",
    "                                                      df_all['salary_avg'].tolist(),\\\n",
    "                                                      test_size=0.1,  \n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:21686\n",
      "Valid data len:2410\n"
     ]
    }
   ],
   "source": [
    "print('Train data len:'+str(len(X_train)))\n",
    "# print('Class distribution'+str(Counter(y_train)))\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "# print('Class distribution'+ str(Counter(y_valid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train \n",
      "         c0   c1   c2   c3   c4   c5   c6   c7   c8   c9  ...  c55  c56  c57  \\\n",
      "15280  149  465  409   87  327  193  565  546  550  248  ...    0    0    0   \n",
      "5589   149  465  110   64  212    0    0    0    0    0  ...    0    0    0   \n",
      "19310  149  300   29  440  395   62  457  479   64  333  ...    0    0    0   \n",
      "8949    88    1    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "8462    88  317  280  480  360  226  280    0    0    0  ...    0    0    0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "13123  149   29   88  439   20  248  110   34    5   20  ...    0    0    0   \n",
      "19648  149  465  300   29  440  382   62  457  178  298  ...    0    0    0   \n",
      "9845    88  465   29   15  110  508   20  374   32   32  ...    0    0    0   \n",
      "10799  149   88  206  409  360    0    0    0    0    0  ...    0    0    0   \n",
      "2732    88  439  387  354  145  480    0    0    0    0  ...    0    0    0   \n",
      "\n",
      "       c58  c59  c60  c61  c62  c63  c64  \n",
      "15280    0    0    0    0    0    0    0  \n",
      "5589     0    0    0    0    0    0    0  \n",
      "19310    0    0    0    0    0    0    0  \n",
      "8949     0    0    0    0    0    0    0  \n",
      "8462     0    0    0    0    0    0    0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  \n",
      "13123    0    0    0    0    0    0    0  \n",
      "19648    0    0    0    0    0    0    0  \n",
      "9845     0    0    0    0    0    0    0  \n",
      "10799    0    0    0    0    0    0    0  \n",
      "2732     0    0    0    0    0    0    0  \n",
      "\n",
      "[21686 rows x 65 columns]\n",
      "x_valid \n",
      "         c0   c1   c2   c3   c4   c5   c6   c7   c8   c9  ...  c55  c56  c57  \\\n",
      "2742    88  155  324  244   64    0    0    0    0    0  ...    0    0    0   \n",
      "8412     0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "10894  149  567  439  317  188   87  226    5   20  439  ...    0    0    0   \n",
      "168    149   88  465   29    1   15  440  409  439   20  ...    0    0    0   \n",
      "5453   465    1  508   84  317    0    0    0    0    0  ...    0    0    0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "7983     1  567   84   84  341    0    0    0    0    0  ...    0    0    0   \n",
      "3739   149  465  567    1   84  119  181    7  341    0  ...    0    0    0   \n",
      "17504  454    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "19131   92  231    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "4042   149   88  465  206   15    1  110  508   84    0  ...    0    0    0   \n",
      "\n",
      "       c58  c59  c60  c61  c62  c63  c64  \n",
      "2742     0    0    0    0    0    0    0  \n",
      "8412     0    0    0    0    0    0    0  \n",
      "10894    0    0    0    0    0    0    0  \n",
      "168      0    0    0    0    0    0    0  \n",
      "5453     0    0    0    0    0    0    0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  \n",
      "7983     0    0    0    0    0    0    0  \n",
      "3739     0    0    0    0    0    0    0  \n",
      "17504    0    0    0    0    0    0    0  \n",
      "19131    0    0    0    0    0    0    0  \n",
      "4042     0    0    0    0    0    0    0  \n",
      "\n",
      "[2410 rows x 65 columns]\n",
      "x_train shape \n",
      " (21686, 65)\n",
      "x_valid shape \n",
      " (2410, 65)\n"
     ]
    }
   ],
   "source": [
    "print('x_train','\\n',X_train, end=\"\\n\")\n",
    "print('x_valid','\\n',X_valid, end=\"\\n\")\n",
    "\n",
    "print('x_train shape','\\n',X_train.shape, end=\"\\n\")\n",
    "print('x_valid shape','\\n',X_valid.shape, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.tolist()\n",
    "X_valid = X_valid.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.pickle', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedding_matrix5.pkl', 'rb') as f:\n",
    "    embedding_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 6.00631571, -3.11916113, -4.56216669, 15.06453228, -2.83644104],\n",
       "       [-1.33523071, -0.1969057 , -1.10164273,  7.44642019,  5.04957056],\n",
       "       ...,\n",
       "       [-2.4779253 , -3.69238138, -3.50253606, 12.97125435, -0.24131088],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding_matrix.shape\n",
    "embed_dim = 5\n",
    "max_train_sentence_length = 65\n",
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#構建TextCNN模型\n",
    "def TextCNN_model_wv(X_train,y_train,X_test,y_test,embedding_matrix):\n",
    "    # 模型結構：詞嵌入-卷積池化*3-拼接-全連接-dropout-全連接\n",
    "    main_input = tf.keras.layers.Input(shape=(max_train_sentence_length,), dtype='float64')\n",
    "    # 詞嵌入（使用預訓練的詞向量）\n",
    "    embedder = tf.keras.layers.Embedding(len(vocab) + 1, embed_dim, input_length=max_train_sentence_length, weights=[embedding_matrix], trainable=False)\n",
    "    #embedder = Embedding(len(vocab) + 1, 300, input_length=50, trainable=False)\n",
    "    embed = embedder(main_input)\n",
    "\n",
    "    # 詞窗大小分別爲3,4,5\n",
    "\n",
    "    ## conv aize = 3\n",
    "    cnn1 = tf.keras.layers.Conv1D(256, 3, padding='same', strides=1, \n",
    "                                    activation='relu',\\\n",
    "                                    kernel_initializer='he_normal',\\\n",
    "                                    kernel_regularizer = regularizers.l2(0.0004))(embed)\n",
    "\n",
    "    cnn1 = tf.keras.layers.Conv1D(256, 3, padding='same', strides=1, \n",
    "                                activation='relu',\\\n",
    "                                kernel_initializer='he_normal',\\\n",
    "                                kernel_regularizer = regularizers.l2(0.0004))(cnn1)\n",
    "    #max pooling                         \n",
    "    # cnn1 = tf.keras.layers.MaxPooling1D(pool_size=3, padding='valid')(cnn1)\n",
    "\n",
    "    cnn1 = tf.keras.layers.Conv1D(128, 3, padding='same', strides=1, \n",
    "                                    activation='relu',\\\n",
    "                                    kernel_initializer='he_normal',\\\n",
    "                                    kernel_regularizer = regularizers.l2(0.0004))(cnn1)\n",
    "\n",
    "    cnn1 = tf.keras.layers.Conv1D(128, 3, padding='same', strides=1, \n",
    "                                activation='relu',\\\n",
    "                                kernel_initializer='he_normal',\\\n",
    "                                kernel_regularizer = regularizers.l2(0.0004))(cnn1)\n",
    "    #max pooling                         \n",
    "    # cnn1 = tf.keras.layers.MaxPooling1D(pool_size=3, padding='valid')(cnn1)\n",
    "\n",
    "    ############################################\n",
    "\n",
    "    ## conv aize = 4\n",
    "    cnn2 = tf.keras.layers.Conv1D(256, 4, padding='same', strides=1, \n",
    "                                    activation='relu',\\\n",
    "                                    kernel_initializer='he_normal',\\\n",
    "                                    kernel_regularizer = regularizers.l2(0.0004))(embed)\n",
    "\n",
    "    cnn2 = tf.keras.layers.Conv1D(256, 4, padding='same', strides=1, \n",
    "                                activation='relu',\\\n",
    "                                kernel_initializer='he_normal',\\\n",
    "                                kernel_regularizer = regularizers.l2(0.0004))(cnn2)\n",
    "    #max pooling                         \n",
    "    # cnn2 = tf.keras.layers.MaxPooling1D(pool_size=3, padding='valid')(cnn2)\n",
    "\n",
    "    cnn2 = tf.keras.layers.Conv1D(128, 4, padding='same', strides=1, \n",
    "                                    activation='relu',\\\n",
    "                                    kernel_initializer='he_normal',\\\n",
    "                                    kernel_regularizer = regularizers.l2(0.0004))(cnn2)\n",
    "\n",
    "    cnn2 = tf.keras.layers.Conv1D(128, 4, padding='same', strides=1, \n",
    "                                activation='relu',\\\n",
    "                                kernel_initializer='he_normal',\\\n",
    "                                kernel_regularizer = regularizers.l2(0.0004))(cnn2)\n",
    "    #max pooling                         \n",
    "    # cnn2 = tf.keras.layers.MaxPooling1D(pool_size=3, padding='valid')(cnn2)\n",
    "\n",
    "    ############################################\n",
    "\n",
    "\n",
    "    ## conv aize = 5\n",
    "    cnn3 = tf.keras.layers.Conv1D(256, 5, padding='same', strides=1, \n",
    "                                    activation='relu',\\\n",
    "                                    kernel_initializer='he_normal',\\\n",
    "                                    kernel_regularizer = regularizers.l2(0.0004))(embed)\n",
    "\n",
    "    cnn3 = tf.keras.layers.Conv1D(256, 5, padding='same', strides=1, \n",
    "                                activation='relu',\\\n",
    "                                kernel_initializer='he_normal',\\\n",
    "                                kernel_regularizer = regularizers.l2(0.0004))(cnn3)\n",
    "    #max pooling                         \n",
    "    # cnn3 = tf.keras.layers.MaxPooling1D(pool_size=3, padding='valid')(cnn3)\n",
    "\n",
    "    cnn3 = tf.keras.layers.Conv1D(128, 5, padding='same', strides=1, \n",
    "                                    activation='relu',\\\n",
    "                                    kernel_initializer='he_normal',\\\n",
    "                                    kernel_regularizer = regularizers.l2(0.0004))(cnn3)\n",
    "\n",
    "    cnn3 = tf.keras.layers.Conv1D(128, 5, padding='same', strides=1, \n",
    "                                activation='relu',\\\n",
    "                                kernel_initializer='he_normal',\\\n",
    "                                kernel_regularizer = regularizers.l2(0.0004))(cnn3)\n",
    "    #max pooling                         \n",
    "    # cnn3 = tf.keras.layers.MaxPooling1D(pool_size=3, padding='valid')(cnn3)\n",
    "\n",
    "    ############################################\n",
    "\n",
    "\n",
    "    # 合併三個模型的輸出向量\n",
    "    cnn = tf.keras.layers.concatenate([cnn1, cnn2, cnn3], axis=-1)\n",
    "    flat = tf.keras.layers.Flatten()(cnn)\n",
    "\n",
    "    # drop1 = tf.keras.layers.Dropout(0.5)(flat)\n",
    "\n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.L1(0.1))(flat)\n",
    "    \n",
    "    # drop1 = tf.keras.layers.Dropout(0.5)(dense)\n",
    "\n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.L1(0.1))(dense)\n",
    "\n",
    "    dense = tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.L1(0.05))(dense)\n",
    "\n",
    "    # drop1 = tf.keras.layers.Dropout(0.5)(dense)\n",
    "\n",
    "    dense = tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.L1(0.05))(dense)\n",
    "\n",
    "    # drop1 = tf.keras.layers.Dropout(0.5)(dense)\n",
    "    dense = tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.L1(0.05))(dense)\n",
    "\n",
    "    dense = tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal')(dense)\n",
    "\n",
    "    main_output = tf.keras.layers.Dense(1, activation='linear')(dense)\n",
    "\n",
    "\n",
    "    # model main_output \n",
    "    ##########################\n",
    "    batch_size=32 \n",
    "    epochs=50\n",
    "    \n",
    "    ##########################\n",
    "    \n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "    valid_ds = tf.data.Dataset.from_tensor_slices((X_test,y_test))\n",
    "\n",
    "\n",
    "    model = tf.keras.Model(inputs=main_input, outputs=main_output)\n",
    "\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.experimental.AdamW(learning_rate=0.004), \n",
    "                    metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    # model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "    history = model.fit(train_ds.shuffle(2000).batch(batch_size),\n",
    "                    epochs= epochs,\n",
    "                    validation_data=valid_ds.batch(batch_size),\n",
    "                    verbose=1)\n",
    "\n",
    "\n",
    "    # output result and plot loss trending\n",
    "    # result = model.predict(X_valid)\n",
    "    # print('MSE: ', tf.keras.metrics.MeanSquaredError(y_valid, result))\n",
    "\n",
    "    plt.plot(history.history[ 'loss' ])\n",
    "    plt.plot(history.history[ 'val_loss' ])\n",
    "    plt.title( 'model loss' )\n",
    "    plt.ylabel( 'loss' )\n",
    "    plt.xlabel( 'epoch' )\n",
    "    plt.legend([ 'train' , 'valid' ], loc= 'lower right' )\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 65)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 65, 5)        3070        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 65, 256)      4096        ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 65, 256)      5376        ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 65, 256)      6656        ['embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 65, 256)      196864      ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 65, 256)      262400      ['conv1d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 65, 256)      327936      ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 65, 128)      98432       ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 65, 128)      131200      ['conv1d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 65, 128)      163968      ['conv1d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 65, 128)      49280       ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 65, 128)      65664       ['conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 65, 128)      82048       ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 65, 384)      0           ['conv1d_15[0][0]',              \n",
      "                                                                  'conv1d_19[0][0]',              \n",
      "                                                                  'conv1d_23[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 24960)        0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 256)          6390016     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 256)          65792       ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 128)          32896       ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          16512       ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 64)           8256        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 64)           4160        ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            65          ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,914,687\n",
      "Trainable params: 7,911,617\n",
      "Non-trainable params: 3,070\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      " 28/678 [>.............................] - ETA: 2:40 - loss: 3521423616.0000 - mean_squared_error: 3521417216.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(y_train)\n\u001b[0;32m      2\u001b[0m y_valid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(y_valid)\n\u001b[1;32m----> 4\u001b[0m TextCNN_model_wv(X_train,y_train,X_valid,y_valid,embedding_matrix)\n",
      "Cell \u001b[1;32mIn [21], line 141\u001b[0m, in \u001b[0;36mTextCNN_model_wv\u001b[1;34m(X_train, y_train, X_test, y_test, embedding_matrix)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[0;32m    139\u001b[0m \u001b[39m# model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds\u001b[39m.\u001b[39;49mshuffle(\u001b[39m2000\u001b[39;49m)\u001b[39m.\u001b[39;49mbatch(batch_size),\n\u001b[0;32m    142\u001b[0m                 epochs\u001b[39m=\u001b[39;49m epochs,\n\u001b[0;32m    143\u001b[0m                 validation_data\u001b[39m=\u001b[39;49mvalid_ds\u001b[39m.\u001b[39;49mbatch(batch_size),\n\u001b[0;32m    144\u001b[0m                 verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    147\u001b[0m \u001b[39m# output result and plot loss trending\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39m# result = model.predict(X_valid)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39m# print('MSE: ', tf.keras.metrics.MeanSquaredError(y_valid, result))\u001b[39;00m\n\u001b[0;32m    151\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[ \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m ])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_train = np.asarray(y_train)\n",
    "y_valid = np.asarray(y_valid)\n",
    "\n",
    "TextCNN_model_wv(X_train,y_train,X_valid,y_valid,embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
